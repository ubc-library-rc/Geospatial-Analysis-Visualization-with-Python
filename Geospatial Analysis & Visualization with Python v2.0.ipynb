{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"20\">Geospatial Analysis & Visualization w/ Python</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0) Setup\n",
    "* To get started, we need to import all the packages we'll use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.collections import PatchCollection\n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1) Importing our data\n",
    "* We'll load the Police Killing Data as a \"DataFrame\" using pandas\n",
    "\n",
    "\n",
    "* Then we'll convert it into a \"GeoDataFrame\" using Geopandas\n",
    "    * To do this, we must assign the \"geometry\".  In this case its point data, and the coordinates are in lat/long\n",
    "    \n",
    "    \n",
    "* Then we need to assign a Coordiante Reference System (CRS) manually\n",
    "    * ESPG is a standardized code that is used to represent CRSs.\n",
    "    * 'espg:4326' is for the refers to the WGS 1984 datum, which our latitude/longitude data is based in.\n",
    "        * This is a CRS that is widely used by many web-based platforms because like Google Maps and Mapbox\n",
    "        * The original only had addresses, not coordinates, so we used a webservice (Mapbox) to generate the coordinates of our addresses\n",
    "        \n",
    "        \n",
    "* Once we have the data loaded, calling .head() will give us a \"preview\" of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the Police Killings file, and set the incident ID as the index\n",
    "police_Killings_Tabular = pd.read_csv('Data/PoliceKillings.csv',\n",
    "                                      parse_dates=['date'],\n",
    "                                      index_col=['id_incident']\n",
    "                                     )\n",
    "\n",
    "# We can then convert the pandas dataframe into a geopandas \"GeodataFrame\"\n",
    "police_Killings = gpd.GeoDataFrame(police_Killings_Tabular,\n",
    "    geometry=gpd.points_from_xy(police_Killings_Tabular.longitude,\n",
    "                                police_Killings_Tabular.latitude\n",
    "                               )\n",
    "                                  )\n",
    "\n",
    "# Now we can assign a CRS\n",
    "WGS_1984={'init' :'epsg:4326'}\n",
    "police_Killings.crs = WGS_1984\n",
    "\n",
    "# Lets sort the incidents by date and then take a quick look.\n",
    "police_Killings=police_Killings.sort_values(by='date')\n",
    "police_Killings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we'll load some data from the 2016 Census\n",
    "\n",
    "* We have a tabular dataset of population data.\n",
    "\n",
    "* We'll load it using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll import the tabualr census data with pandas\n",
    "Census_Tabular = pd.read_csv('Data/Census.csv',index_col=['PRUID'])\n",
    "Census_Tabular.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We also have a provincial boundary shapefile\n",
    "\n",
    "* Shapefile are used to store georphric data.  They already have projections and coordiantes associated with them.\n",
    "    * Geopandas has similar functionality to pandas and we can use it to import shapefiles.  But the read_file() method had less options, so we have to set the index manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll import provincial boundaries using geopandas\n",
    "Provincial_Boundaries = gpd.read_file('Data/Provincial_Boundaries.shp').set_index('PRUID')\n",
    "Provincial_Boundaries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2) Joining our census data\n",
    "\n",
    "* This will let us map the disparity by province and do a more detailed analysis\n",
    "\n",
    "* PRUID is a \"unique identifier\" that represents the provinces.\n",
    "\n",
    "    * Since both have the PRUID set as the index, we don't need to specify a join key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Test_Join = Provincial_Boundaries.join(Census_Tabular)\n",
    "Test_Join.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# But our join fails :(\n",
    "\n",
    "* ### Notice the NaN values.\n",
    "\n",
    "* NaN represetns missing data values\n",
    "    * Lets look at the index for both files?  Maybe we have a datatype missmatch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Provincial_Boundaries.index.dtype)\n",
    "print(Census_Tabular.index.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sure enough!  The Provincial_Boundaries index is an \"object\", not an integer.\n",
    "\n",
    "* We can fix that easily and then do the join!\n",
    "    * We just need to change the datatype of the Provincial_Boundaries layer.\n",
    "\n",
    "### We can assign the datatype using the .astype() function.\n",
    "\n",
    "### But datatype do we assign?\n",
    "* Hint The anser is in the cell above!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = \n",
    "Provincial_Boundaries.index = Provincial_Boundaries.index.astype(dtype)\n",
    "Provincial_Data = Provincial_Boundaries.join(Census_Tabular)\n",
    "Provincial_Data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3) Exploring the data\n",
    "\n",
    "### First lets make a quick map.\n",
    "\n",
    "* Our Layers need to be in the same coordinate system to match up properly on a map!\n",
    "\n",
    "* We can re-project the police_Killings layer using the .to_crs function to set the CRS to that of the Provinces\n",
    "    * The provinces layer uses the Canada Lambert Conformal Conic projection (LCC).  This is the standard projection used by stats canada and is ideally suited for displaying the whole of country.\n",
    "        \n",
    "        \n",
    "* Once both datasets are in the same coordinate system, we can make a map!\n",
    "\n",
    "\n",
    "* First we must define a plot, using the matplotlib.pyplot package.  We imported this earlier as \"plt\"\n",
    "    * We use the plt.subplots() to create a figure, and we can define how big we want it to be\n",
    "    \n",
    "    \n",
    "* Geoapandas can then use the .plot() fucntion to create a map using matplotlib.\n",
    "    * We simply tell it what axis to draw the plot on with ax=\"axes\"\n",
    "    * Then set a few other parameters:\n",
    "        * We just want the provinces as a grey background so we can set the color\n",
    "        * We want to classify killings by race, so we can set race as the column.  THen we can add a legend to aid interpretation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We can use .to_crs() to create a police killings layer with the same projection as the provinces layer.\n",
    "police_Killings = police_Killings.to_crs(Provincial_Data.crs)\n",
    "\n",
    "# Now, we can create a figure using matplotlib (plt), first we define the figure and the size\n",
    "fig,axes=plt.subplots(\n",
    "    figsize=(6,6)\n",
    ")\n",
    "\n",
    "# Now we can add the provinces using the .plot() function.  We set the plotting axes and give it a grey color\n",
    "cb = Provincial_Data.plot(\n",
    "    ax=axes,\n",
    "    column='Total',\n",
    "    cmap = 'Greys',\n",
    "    edgecolor='grey',\n",
    "    legend=True,\n",
    ")\n",
    "\n",
    "# Then we add the police_Killings_LCC.  We'll set the column to 'race', so we can disply by race,\n",
    "# give the point markers a few more parameters, and add them to a legend\n",
    "police_Killings.plot(\n",
    "    ax=axes,\n",
    "    column='race',\n",
    "    edgecolor='k',\n",
    "    markersize=15,\n",
    "    legend=True,\n",
    "    legend_kwds={'loc': 'upper right','fontsize':8}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now you've made your first map with python!\n",
    "\n",
    "* But its an ugly map :(\n",
    "    * It doesn't look great.  This is just the quick and dirty way to look ata data\n",
    "    * To make things more presentable, we'll have to be more explicit in setting up our map.  But that's a task for later.\n",
    "\n",
    "\n",
    "### For now, lets move on and look at the dataset in more detail.\n",
    "\n",
    "* Pandas & Geopandas have some nice features to quickly summarize our dataset.\n",
    "\n",
    "\n",
    "\n",
    "* We can use .count() to get the total # incidents.\n",
    "    * Callling .count() as is, will give us a list of all the columns, and a count for each.  We can see most collumns are \"full\" but in the \"geocoding_Notes\" column, we can see that 4 points don't have coordinates associated with their address.  This suggests there was an error in the data entry process.  We don't need to worry about this though.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "police_Killings.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can use .mean(), .min(), etc. followed by ['age'] to get some vital statistics on the age of victims.\n",
    "\n",
    "* We can use .describe() to summarize multiple attributes of the age column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Age Distribution of Victims')\n",
    "print()\n",
    "print('Mean:                ',\n",
    "      police_Killings.mean()['age']\n",
    "     )\n",
    "print()\n",
    "print('Standard Deviation:  ',\n",
    "      police_Killings.std()['age']\n",
    "     )\n",
    "print()\n",
    "print('Youngest:            ',\n",
    "      police_Killings.max()['age']\n",
    "     )\n",
    "print()\n",
    "print('Oldest:              ',\n",
    "      police_Killings.min()['age']\n",
    "     )\n",
    "\n",
    "police_Killings.describe()['age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can resample our data to look for trends\n",
    "* The date column is a special type of data that allows us to resample our data by year, month, etc\n",
    "* The dataset has to be in order by date for this to work (we did this alread)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Resampled = police_Killings.set_index('date').resample('Y').count()\n",
    "\n",
    "## scipy can be used to calculate a linear regression line and print the results\n",
    "Regression_Line = stats.linregress(Resampled.index.year,Resampled['id_victim'])\n",
    "print(Regression_Line)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "## We can make a scatter plot of the annual killings\n",
    "plt.scatter(\n",
    "    Resampled.index.year,\n",
    "    Resampled['id_victim'],\n",
    "    color='black',\n",
    "    label='Yearly Total'\n",
    ")\n",
    "\n",
    "## Then plot he increasing trendline over it and add the slope and pvalue to the legend.\n",
    "plt.plot(\n",
    "    Resampled.index.year,\n",
    "    Resampled.index.year*Regression_Line[0]+Regression_Line[1],\n",
    "    label='Trend Line: '+str(np.round(Regression_Line[0],3))+'\\np-value: '+str(np.round(Regression_Line[3],3)),\n",
    "    color='red'\n",
    "    )\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Police Killings per Year in Canda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can group our data to look for patterns too.\n",
    "\n",
    "* the .groupby() function can accept one or multple paramters to group our dataset by.\n",
    "    * This allows us to create complex queries if we want.\n",
    "* We can have to follow up with .count(), .mean(), etc.\n",
    "    * This tells us \"how\" to aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "## This is a dictionary to set colors based on specific values.  We're using Hex color codes here.\n",
    "## They're a common way for specifiying colors\n",
    "Pie_Colors = {'None':'#FF0000',\n",
    "              'Knife':'#fecc5c',\n",
    "              'Firearm':'#ffffb2',\n",
    "              'Other weapons':'#fd8d3c'}\n",
    "\n",
    "## Group by the variable we want, summarize by count, then make our pie chart!\n",
    "Armed = police_Killings.groupby(['armed_type']).count()\n",
    "ax.pie(\n",
    "    Armed['id_victim'],\n",
    "    labels=Armed.index,\n",
    "    textprops={'fontsize': 8},\n",
    "    colors=[Pie_Colors[i] for i in Armed.index],\n",
    "    autopct='%1.1f%%',\n",
    "    wedgeprops={\"edgecolor\":\"k\",'linewidth': 1, 'linestyle': 'dashed'}\n",
    ")\n",
    "ax.set_title('Police Killings: Was the Victim Armed?')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby allows us to create very complex queries if we want\n",
    "\n",
    "* We can search combinations of two or more variables\n",
    "\n",
    "* This retruns a record with two indexes: Department and armed type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Group = police_Killings.groupby(['Department','armed_type']).count()['id_victim']#.sort_values(ascending=True)\n",
    "\n",
    "print(Group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What police departments kill the most unarmed people?\n",
    "\n",
    "* We can use the .loc command to do a search for all departments with more than one unarmed killing.\n",
    "\n",
    "* Then we sort the record, select the top 5, and plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The unstack command allows us to turn the last index into our colum names\n",
    "Force=Group.unstack()\n",
    "Force['Total'] = Force.sum(axis=1)\n",
    "Force['Unarmed_Frac']=Force['None']/Force['Total']\n",
    "\n",
    "## .loc is the search function.\n",
    "## .sort_values() sorts our records in ascending order.\n",
    "## [-5:] grabs just the last five records\n",
    "Force = Force.loc[Force['None']>1].sort_values(by='None')[-5:]\n",
    "print(Force)\n",
    "\n",
    "Force_Labels={'Toronto Police Service':'Toronto',\n",
    "              'RCMP':'RCMP',\n",
    "              'Vancouver Police Department':'Vancouver',\n",
    "              'Service de police de la Ville de Montreal':'Montreal',\n",
    "              'Edmonton Police Service':'Edmonton'}\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(6,5))\n",
    "\n",
    "ax.barh(Force.index,Force['None'],facecolor='#FF0000',edgecolor='black')\n",
    "ax.set_yticklabels([Force_Labels[f] for f in Force.index.values])\n",
    "ax.set_title('Unarmed Victims by Deparment (2000-2015)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We're intersted in a specific question.  What's the distribution of police killings by race?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "police_Killings.groupby(['race']).count()['date'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4) Normalizing our Data\n",
    "\n",
    "* The racial demographics of Canada aren't evenly split however!\n",
    "\n",
    "* We need to Normalize our data by population statistics.\n",
    "\n",
    "* Lets look at our census data again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Provincial_Data[Census_Tabular.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first row contains the total values for the whole country.  We can use this to calculate a police killing rate.\n",
    "\n",
    "* But the Canadian Census' racial categories don't match up perfectly with the police violence dataset's racial\n",
    "* How can we work around this?\n",
    "    * We have the largest three groups in the police killing set: White, Indigenous, and Black.  So we can work with them as is\n",
    "    * The other races make up a small portion of total killings.  And we can't be entirely sure how the CBC defined their groupings.  So, lets add a new category: \"Other Minorities\"\n",
    "    \n",
    "* We'll do this for both the provincial boundaires and the police_Killings\n",
    "    * For the police killings, we'll leave the unknow records alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Other_Minorities=['South Asian', 'Chinese', 'Filipino','Latin American',\n",
    " 'Arab', 'Southeast Asian', 'West Asian', 'Korean',\n",
    "'Japansese', 'Visible minority, n.i.e', 'Mixed']\n",
    "Provincial_Data['Other Minorities']=Provincial_Data[Other_Minorities].sum(axis=1)\n",
    "\n",
    "Other_Minorities=['Latin American', 'Arab', 'Other', 'South Asian', 'Asian']\n",
    "police_Killings['race'] = police_Killings['race'].replace(to_replace=Other_Minorities,value='Other Minorities')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From here, we can calculate the Police Killing Rate (PKR).\n",
    "\n",
    "* Dividing the total number of killings by the population gives us ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Races = ['Indigenous','Black','Caucasian','Other Minorities']\n",
    "Race_Breakdown = police_Killings.groupby(['race']).count()['id_victim']\n",
    "Can_Pop = Provincial_Data[Races].sum()\n",
    "\n",
    "Racial_Rates = Race_Breakdown.T[Races]/Can_Pop\n",
    "Racial_Rates['CA. Average']=Race_Breakdown.T[Races].sum()/Can_Pop.sum()\n",
    "print(Racial_Rates)\n",
    "# police_Killings.groupby(['race']).count()['date'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This number isn't that meaningful though.  It represents the number of killings \"per person\" over the whole study period.\n",
    "\n",
    "* Lets convert the rate to a more meaninful unit.  Killings / Million Residents / Year\n",
    "\n",
    "* The date record is a \"date\" object.\n",
    "* It has some added functionality like being able to query the the year, month, day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "First_Year = police_Killings['date'].min().year\n",
    "Last_Year = police_Killings['date'].max().year\n",
    "print(First_Year,Last_Year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How might we calculate our police killing rate?\n",
    "\n",
    "* What should we set as scale and duration to convert units?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scale =\n",
    "Duration = \n",
    "rate_Conversion = Scale / Duration\n",
    "\n",
    "Racial_Rates=Racial_Rates.sort_values(ascending=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "ax.barh(\n",
    "    Racial_Rates.index,\n",
    "    Racial_Rates.values * rate_Conversion,\n",
    "    facecolor='#FF0000',\n",
    "    edgecolor='black',\n",
    "    linewidth=1\n",
    ")\n",
    "ax.set_title('Police Killings Rates by Race in Canada')\n",
    "ax.set_xlabel('Killings per Year per Million People')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Police killing rates are 5x higher for Indigenous people and 4x higher for Black people than it is fo White people.\n",
    "\n",
    "* ## This is an abhorent example of systemic racism in Canadian Policing.\n",
    "\n",
    "\n",
    "# Lets look at the PKR by province.\n",
    "Now we  want to normalize by provincial demographics.\n",
    "\n",
    "* We have a few more steps to go through first.\n",
    "    * The police killings and census data use different abbreviations.  To do a join our dataset with the census data we'll need to assign an new abbreviaton\n",
    "    * We'll us a dictionary to do this\n",
    "    \n",
    "    \n",
    "* Then we can summarize the killings by province and join it to the Provinces_Join layer\n",
    "\n",
    "* Now we can summarize the killings by province and join it to the Provinces_Join layer\n",
    "\n",
    "\n",
    "* Note Prince Edward Island doesn't have any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_by_Province = police_Killings.groupby(['prov','race']).count()\n",
    "race_by_Province = race_by_Province['date'].unstack()\n",
    "race_by_Province['Total'] = race_by_Province.sum(axis=1)\n",
    "\n",
    "for col in Races:\n",
    "    Provincial_Data = Provincial_Data.join(race_by_Province[col],on='prov',rsuffix='_Killings')\n",
    "\n",
    "for col in ['Unknown','Total']:\n",
    "    Provincial_Data = Provincial_Data.join(race_by_Province[col],on='prov',rsuffix='_Killings')\n",
    "Provincial_Data\n",
    "\n",
    "# Some provines/groups don't have any records.  Those are given NaN values, and need to be repalced with zeros\n",
    "Provincial_Data[[x+'_Killings' for x in Races]]=Provincial_Data[[x+'_Killings' for x in Races]].fillna(0)\n",
    "Provincial_Data['Total_Killings']=Provincial_Data['Total_Killings'].fillna(0)\n",
    "Provincial_Data[['Unknown' for x in Races]].fillna(0)\n",
    "\n",
    "Provincial_Data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5) Calcualte and map the Police Killing Rate (PKR) on the provincial level\n",
    "* Nunavut has a huge problem.  Its not a conicidence that the population is 75% Inuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Provincial_Data['PKR']=(Provincial_Data['Total_Killings']/Provincial_Data['Total']*rate_Conversion)\n",
    "\n",
    "print(Provincial_Data[['prov','PKR']].sort_values(by='PKR'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can make a chloropleth map of this pattern.\n",
    "\n",
    "* Lets check out colorbrewer for help picking a good color scheme\n",
    "\n",
    "https://colorbrewer2.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can define our own class break values, labels, and colors for the map\n",
    "bins = [-0.01,0.5,1,1.4,4,9]\n",
    "labels = ['<0.5','0.5 - 1','1 - 1.3','3.1','7.7']\n",
    "colors = ['#fee5d9','#fcae91','#fb6a4a','#de2d26','#FF0000']\n",
    "\n",
    "## We can use the labels and colors to create a color dictionary\n",
    "PKR_Color = {key:value for key,value in zip(labels,colors)}\n",
    "\n",
    "## The pd.cut() command will creat a new record for us containg class labels.\n",
    "Provincial_Data['PKR_Classes']=(pd.cut(Provincial_Data['PKR'],bins=bins,labels=labels)).astype('str')\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(6,6))\n",
    "\n",
    "## To make a better map with geopandas, we have to loop through recrods and plot each class seprately\n",
    "## Then create a custom legend item for it.\n",
    "\n",
    "Patches=[]\n",
    "for pkr_class in Provincial_Data['PKR_Classes'].unique():\n",
    "    ## kwargs allows us to set multiple arguments for the plot and save them\n",
    "    ## We can then used them in multiple commands\n",
    "    kwargs = {'facecolor':PKR_Color[pkr_class],\n",
    "             'edgecolor':'k',\n",
    "             'label':pkr_class}\n",
    "    \n",
    "    Provincial_Data.loc[Provincial_Data['PKR_Classes']==pkr_class].plot(\n",
    "        ax=ax,\n",
    "        **kwargs\n",
    "             )\n",
    "    \n",
    "    ## mpatches.Patch() allows us to create a custom legend item for each class\n",
    "    Patches.append(mpatches.Patch(**kwargs))\n",
    "    \n",
    "## We add the legend items to the legend\n",
    "ax.legend(handles=Patches) \n",
    "\n",
    "## This turns off the numeric x,y labels\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "ax.set_title('Police Killings per Year per Million People')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6) Calculate a Police Killings Discrimination Index (PKDI):\n",
    "\n",
    "* For this, we'll compare the PKR for white people to the combined PKR of black and indigenous people\n",
    "\n",
    "* We'll use the following equations:\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\ PKR_{W} & = (\\frac{White Killings}{White Population}) * 1e6 / 18\\\\\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "\\ PKR_{BI} & = (\\frac{Black Killings + Indigenous Killings}{Black Population + Indigenous Population}) * 1e6 / 18\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "\\ PKDI & = PKR_{BI} - PKR_{W}\\\\\n",
    "\\end{align}\n",
    "\n",
    "## This will hightlight the disparities in police killings\n",
    "* We'll classify the data using the following scheme:\n",
    "    \n",
    "        * \"Low Bias\": -0.5 to 0.5 - This is the rate killings of whites.  Within these ranges, differences might be due to presence or lacktherof of a certain groups \n",
    "        * \"Moderate Bias\": 0.5 to 1 - Greater than the white rate, less than the national average\n",
    "        * \"Severe Bias\": 1 to 3 - Greater than the national rate, less than the indigenouos rate\n",
    "        * \"Extreme Bias: 3 to 10 - Greater than the national indigenous rate\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Provincial_Data['PKR_W']=Provincial_Data['Caucasian_Killings']/Provincial_Data['Caucasian']*rate_Conversion\n",
    "Provincial_Data['PKR_BI']=(Provincial_Data['Indigenous_Killings']+Provincial_Data['Black_Killings'])/(Provincial_Data['Indigenous']+Provincial_Data['Black'])*rate_Conversion\n",
    "\n",
    "Provincial_Data['PKDI'] = Provincial_Data['PKR_BI'] - Provincial_Data['PKR_W']\n",
    "\n",
    "Provincial_Data['PKDI']=Provincial_Data['PKDI'].fillna(0)\n",
    "\n",
    "\n",
    "bins = [-0.5,0.5,1,2,10.0]\n",
    "labels = ['Low Bias','Moderate Bias','Severe Bias','Extreme Bias']\n",
    "Provincial_Data['PKDI_Classes']=(pd.cut(Provincial_Data['PKDI'],bins=bins,labels=labels)).astype('str')\n",
    "\n",
    "Provincial_Data.round(2)\n",
    "\n",
    "# print(Provincial_Data[['prov','PKDI','PKDI_Classes']].sort_values(by='PKDI').round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets map the patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax1=plt.subplots(figsize=(5,5))\n",
    "colors = ['#ffffb2','#fecc5c','#fd8d3c','#FF0000']\n",
    "PKDI_Color = {key:value for key,value in zip(labels,colors)}\n",
    "\n",
    "Patches = []\n",
    "for pkdi_class in Provincial_Data['PKDI_Classes'].unique():\n",
    "    kwargs = {'facecolor':PKDI_Color[pkdi_class],\n",
    "             'edgecolor':'black',\n",
    "              'linewidth':.5,\n",
    "             'label':pkdi_class}\n",
    "    Provincial_Data.loc[Provincial_Data['PKDI_Classes']==pkdi_class].plot(\n",
    "        ax=ax1,\n",
    "        **kwargs\n",
    "             )\n",
    "    Patches.append(mpatches.Patch(**kwargs))\n",
    "    \n",
    "ax1.legend(handles=Patches,) \n",
    "ax1.get_xaxis().set_visible(False)\n",
    "ax1.get_yaxis().set_visible(False)\n",
    "ax1.set_title('Police Killing Discrimination Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7) Save the data so we can use it in the future\n",
    "* We're going to save it as a shapefile for use with geopandas or a desktop GIS\n",
    "* We're also going to save it as a \"GeoJSON\" file.  This datatype is well suited for webmapping.  Which I cover in a dfferent workshp!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Provincial_Data.to_file('Data/Provincial_Police_Violence.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8) Putting Everything Together: Create an Infographic\n",
    "\n",
    "* Matplotlib alows us to be very specific in determining our layout with gridspec.\n",
    "\n",
    "\n",
    "* We can create a large plot and define specifically what we want.\n",
    "\n",
    "\n",
    "* We'll have two maps, showing the PKR and the PKDI on the left\n",
    "\n",
    "\n",
    "* Then we'll add some smaller plots on the right showing the annual trend, national PKR by race, and some pie charts\n",
    "\n",
    "\n",
    "* We can set our default ontsize for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 10\n",
    "BIGGER_SIZE = 16\n",
    "\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "gs = fig.add_gridspec(100,100)\n",
    "\n",
    "PKR_Map = fig.add_subplot(gs[0:45 , 0:45])\n",
    "PKDI_Map = fig.add_subplot(gs[0:45, 55:])\n",
    "\n",
    "\n",
    "\n",
    "Annual_Trend = fig.add_subplot(gs[47:65, 5:45])\n",
    "PKR_national = fig.add_subplot(gs[47:65, 65:])\n",
    "\n",
    "Armed_Stats = fig.add_subplot(gs[74:92, 5:45])\n",
    "Dept_Stats = fig.add_subplot(gs[74:92, 65:])\n",
    "\n",
    "\n",
    "SourceStatement = fig.add_subplot(gs[93:,:])\n",
    "\n",
    "plt.subplots_adjust(left=.05, bottom=.05, right=.95, top=.95, wspace=.1, hspace=.1)\n",
    "\n",
    "fig.patch.set_facecolor([.9,.9,.9])\n",
    "plt.suptitle('Police Killings in Canada (2000-2017)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can add things to the figure\n",
    "* First lets do the maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Plot the PKR\n",
    "Patches=[]\n",
    "for pkr_class in Provincial_Data['PKR_Classes'].unique():\n",
    "    kwargs = {'facecolor':PKR_Color[pkr_class],\n",
    "             'edgecolor':'k',\n",
    "             'label':pkr_class}\n",
    "    Provincial_Data.loc[Provincial_Data['PKR_Classes']==pkr_class].plot(\n",
    "        ax=PKR_Map,\n",
    "        **kwargs\n",
    "             )\n",
    "    Patches.append(mpatches.Patch(**kwargs))\n",
    "PKR_Map.legend(handles=Patches) \n",
    "PKR_Map.get_xaxis().set_visible(False)\n",
    "PKR_Map.get_yaxis().set_visible(False)\n",
    "PKR_Map.set_title('Police Killings per Year per Million People')\n",
    "\n",
    "# Plot the PKDI\n",
    "Patches = []\n",
    "for pkdi_class in Provincial_Data['PKDI_Classes'].unique():\n",
    "    kwargs = {'facecolor':PKDI_Color[pkdi_class],\n",
    "             'edgecolor':'k',\n",
    "             'label':pkdi_class}\n",
    "    Provincial_Data.loc[Provincial_Data['PKDI_Classes']==pkdi_class].plot(\n",
    "        ax=PKDI_Map,\n",
    "        **kwargs\n",
    "             )\n",
    "    Patches.append(mpatches.Patch(**kwargs))\n",
    "PKDI_Map.legend(handles=Patches,) \n",
    "PKDI_Map.get_xaxis().set_visible(False)\n",
    "PKDI_Map.get_yaxis().set_visible(False)\n",
    "PKDI_Map.set_title('Police Killing Racial Discrimination Index')\n",
    "\n",
    "## Plot the annual trend\n",
    "Annual_Trend.plot(\n",
    "    Resampled.index.year,\n",
    "    Resampled['id_victim'],\n",
    "    color='black',\n",
    ")\n",
    "Annual_Trend.plot(\n",
    "    Resampled.index.year,\n",
    "    Resampled.index.year*Regression_Line[0]+Regression_Line[1],\n",
    "    label='Trend Line: '+str(np.round(Regression_Line[0],3))+'\\np-value: '+str(np.round(Regression_Line[3],3)),\n",
    "    color='red'\n",
    "    )\n",
    "Annual_Trend.legend()\n",
    "Annual_Trend.set_title('Annual Trend')\n",
    "Annual_Trend.set_xticks([2000,2005,2010,2015])\n",
    "\n",
    "## Plot the Average PKR\n",
    "PKR_national.barh(\n",
    "    Racial_Rates.index,\n",
    "    Racial_Rates.values * rate_Conversion,\n",
    "    facecolor='#FF0000',\n",
    "    edgecolor='black',\n",
    "    linewidth=1\n",
    ")\n",
    "PKR_national.set_title('Racial Disparity: National Average')\n",
    "PKR_national.set_xlabel('Killings per Year per million residents')\n",
    "\n",
    "## plot the weapon type\n",
    "Armed_Stats.pie(\n",
    "    Armed['id_victim'],\n",
    "    labels=Armed.index,\n",
    "    colors=[Pie_Colors[i] for i in Armed.index],\n",
    "    textprops={'fontsize': 8},\n",
    "    autopct='%1.1f%%',\n",
    "    wedgeprops={\"edgecolor\":\"k\",'linewidth': 1, 'linestyle': 'dashed'}\n",
    ")\n",
    "Armed_Stats.set_title('Was the Victim Armed?')\n",
    "\n",
    "## Plot the breakdown by department\n",
    "Dept_Stats.barh(Force.index,Force['None'],facecolor='#FF0000',edgecolor='black')\n",
    "Dept_Stats.set_yticklabels([Force_Labels[f] for f in Force.index.values])\n",
    "Dept_Stats.set_title('Unarmed Victims by Deparment')\n",
    "\n",
    "## Add a source statement\n",
    "Descriptor = \\\n",
    "'''Infographic Created by June Skeeter. Data Soruces: The CBC \"Deadly Force (2018)\" & Stats Canada\n",
    "\n",
    "The Police Killing Discrimination Index (PKDI) quantifies the disparitiy in police killing rates (PKR) between Black and Idigenous people and White people in Canada.\n",
    "The PKDI is deined as: PKDI = PKR$_{Black+Indigenous}$-PKR$_{White}$'''\n",
    "\n",
    "# Descriptor = 'Kitties'\n",
    "SourceStatement.set_axis_off()\n",
    "SourceStatement.text(0, 0, \n",
    "                     Descriptor,\n",
    "                     horizontalalignment='left',\n",
    "                     verticalalignment='center',\n",
    "                    )\n",
    "\n",
    "plt.savefig('InfoGraphic.png',facecolor=fig.get_facecolor(),edgeolor='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated Data for BC\n",
    "\n",
    "2013 - May 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the .read_file() function reads shapefiles\n",
    "MVan_CT = gpd.read_file('Data/CensusTracts/SimplyAnalytics_Shapefiles_2021-06-01_17_44_45_9e5629a2de473cd5362919f9edc33853.shp')\n",
    "print(MVan_CT.crs)\n",
    "MVan_CT = MVan_CT.rename(columns={\n",
    "'VALUE0': 'Aboriginal identity, 2016',\n",
    "'VALUE1': 'Population, 2016',\n",
    "'VALUE2': 'Total visible minority population, 2016'\n",
    "                    })\n",
    "\n",
    "MVan_CT['NonWhitePCT'] = MVan_CT[['Aboriginal identity, 2016',\n",
    "'Total visible minority population, 2016']].sum(axis=1)/MVan_CT['Population, 2016']*100\n",
    "\n",
    "# .to_crs()changes the coordinate system\n",
    "# Provincial_Data = Provincial_Data.to_crs('EPSG:4326')\n",
    "# .to_file() saves our data to the specified format\n",
    "print('Data Converted')\n",
    "print(MVan_CT.NonWhitePCT.describe())\n",
    "MVan_CT.to_file(\"Data/MVan_CT.json\", driver = \"GeoJSON\")\n",
    "MVan_CT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the Police Killings file, and set the incident ID as the index\n",
    "BC_Tabular = pd.read_csv('Data/BC_Geocoded.csv',\n",
    "                                      parse_dates=['date'],\n",
    "                                      index_col=['id_incident']\n",
    "                                     )\n",
    "\n",
    "# We can then convert the pandas dataframe into a geopandas \"GeodataFrame\"\n",
    "BC_Data = gpd.GeoDataFrame(BC_Tabular,\n",
    "    geometry=gpd.points_from_xy(BC_Tabular.longitude,\n",
    "                                BC_Tabular.latitude\n",
    "                               )\n",
    "                                  )\n",
    "\n",
    "# Now we can assign a CRS\n",
    "WGS_1984={'init' :'epsg:4326'}\n",
    "BC_Data.crs = WGS_1984\n",
    "\n",
    "# Lets sort the incidents by date and then take a quick look.\n",
    "BC_Data=BC_Data.sort_values(by='date')\n",
    "BC_Data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point in Polygon Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MVan_CT['Incidents'] = 0\n",
    "for i,row in MVan_CT.iterrows():\n",
    "    pip = BC_Data.within(row['geometry'])\n",
    "    if pip.sum()>0:\n",
    "#         print(pip.sum())\n",
    "        MVan_CT.loc[MVan_CT.index==i,'Incidents']+=pip.sum()\n",
    "print(MVan_CT['Incidents'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now, we can create a figure using matplotlib (plt), first we define the figure and the size\n",
    "fig,axes=plt.subplots(\n",
    "    figsize=(8,8)\n",
    ")\n",
    "\n",
    "# Now we can add the provinces using the .plot() function.  We set the plotting axes and give it a grey color\n",
    "cb = MVan_CT.plot(\n",
    "    ax=axes,\n",
    "    column='Incidents',\n",
    "    cmap = 'Greys',\n",
    "    edgecolor='grey',\n",
    "    legend=True,\n",
    ")\n",
    "\n",
    "# Then we add the police_Killings_LCC.  We'll set the column to 'race', so we can disply by race,\n",
    "# give the point markers a few more parameters, and add them to a legend\n",
    "BC_Data.plot(\n",
    "    ax=axes,\n",
    "    edgecolor='k',\n",
    "    markersize=15,\n",
    "    legend_kwds={'loc': 'upper right','fontsize':8}\n",
    ")\n",
    "X_bounds = [MVan_CT.bounds.minx.min(),MVan_CT.bounds.maxx.max()]\n",
    "Y_bounds = [MVan_CT.bounds.miny.min(),MVan_CT.bounds.maxy.max()]\n",
    "axes.set_ylim(Y_bounds)\n",
    "axes.set_xlim(X_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MVan_CT['Rate'] = MVan_CT['Incidents']/MVan_CT['Population, 2016']*1e4/8.5\n",
    "# Now, we can create a figure using matplotlib (plt), first we define the figure and the size\n",
    "fig,axes=plt.subplots(\n",
    "    figsize=(8,8)\n",
    ")\n",
    "\n",
    "# Now we can add the provinces using the .plot() function.  We set the plotting axes and give it a grey color\n",
    "cb = MVan_CT.plot(\n",
    "    ax=axes,\n",
    "    column='Rate',\n",
    "    cmap = 'Greys',\n",
    "    edgecolor='grey',\n",
    "    legend=True,\n",
    ")\n",
    "\n",
    "# Then we add the police_Killings_LCC.  We'll set the column to 'race', so we can disply by race,\n",
    "# give the point markers a few more parameters, and add them to a legend\n",
    "BC_Data.plot(\n",
    "    ax=axes,\n",
    "    edgecolor='k',\n",
    "    markersize=15,\n",
    "    legend_kwds={'loc': 'upper right','fontsize':8}\n",
    ")\n",
    "X_bounds = [MVan_CT.bounds.minx.min(),MVan_CT.bounds.maxx.max()]\n",
    "Y_bounds = [MVan_CT.bounds.miny.min(),MVan_CT.bounds.maxy.max()]\n",
    "axes.set_ylim(Y_bounds)\n",
    "axes.set_xlim(X_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo-env",
   "language": "python",
   "name": "geo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
